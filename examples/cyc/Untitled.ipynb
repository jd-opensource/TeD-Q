{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed9a87-1d8a-4679-b7bd-479483e211c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter(file, dict_str_old_new):\n",
    "    \"\"\"\n",
    "    替换文件中的字符串\n",
    "    :param file:文件名\n",
    "    :param old_str:就字符串\n",
    "    :param new_str:新字符串\n",
    "    :return:\n",
    "    \n",
    "    \"\"\"\n",
    "    file_data = \"\"\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            for old_str, new_str in dict_str_old_new.items():\n",
    "                if old_str in line:\n",
    "                    print(line)\n",
    "                    line = new_str\n",
    "            file_data += line\n",
    "    with open(file,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(file_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd06964-648f-464e-83a5-31097b7e83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_str_old_new = { 'd':'f', 'g':'j'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7635ff-ad9e-4394-9006-f2c103a6f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for old_str, new_str in dict_str_old_new.items():\n",
    "    print(old_str,new_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d78dbca-047a-4761-8169-0fee91527acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_str_old_new = dict()\n",
    "num_nodes=4\n",
    "cpus_per_node=5\n",
    "gpus_per_cpu=6\n",
    "\n",
    "str_num_nodes = \"#SBATCH --nodes=\" + str(num_nodes) + \"\\n\"\n",
    "dict_str_old_new[\"#SBATCH --nodes=\"] = str_num_nodes\n",
    "\n",
    "str_cpus_per_node = \"#SBATCH --ntasks-per-node=\" + str(cpus_per_node) + \"\\n\"\n",
    "dict_str_old_new[\"#SBATCH --ntasks-per-node=\"] = str_cpus_per_node\n",
    "\n",
    "str_gpus_per_cpu = \"#SBATCH --gres=gpu:\" + str(gpus_per_cpu) + \"\\n\"\n",
    "dict_str_old_new[\"#SBATCH --gres=gpu:\"] = str_gpus_per_cpu\n",
    "\n",
    "alter(\"cycslurmjob.sh\", dict_str_old_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac85a97e-e3bf-4962-af77-de25bf4cffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import numpy\n",
      "print('fuck')\n",
      "\n",
      "fuck\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "fp = tempfile.NamedTemporaryFile(mode='w+t', encoding=\"utf-8\", newline='\\n') # 创建一个临时文件\n",
    "fp.write(f\"import os\\nimport numpy\\nprint('fuck')\\n\")     # 向该零时文件中写入一些数据\n",
    "\n",
    "fp.seek(0) # 从文件中读取数据\n",
    "print(fp.read())\n",
    "\n",
    "f=os.popen(\"python \" + fp.name)\n",
    "print(f.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f6b9c6-9445-4677-9762-670df9236059",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"import os\\nimport numpy\\nprint('fuck')\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b080747-3bfb-436e-b0ca-ed12b9277c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"abcdefg.py\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac2ec4-d33b-43a1-b7a1-bd0c569f5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add83d59-1c8f-4beb-8c6a-393f3ece1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4172ef-4993-4f3e-b261-6fce5c48709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087a098-481c-449d-b698-67b3f5d38a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04a3cf-35da-4e1d-a889-7e56fe94b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import NamedTemporaryFile\n",
    " \n",
    "with NamedTemporaryFile('w+t') as f:\n",
    "    print('filename is:', f.name)\n",
    "    ...\n",
    " \n",
    "# File automatically destroyed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db74f64-a7cf-480d-ac53-df3b4d55be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python abc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbeb0ea-bcf7-44c4-83e5-b4951f74ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('vivado -jou {cdir}/vivado.jou -log {cdir}/vivado.log '\n",
    "                       '-mode batch -source '\n",
    "                       '{cfile}'.format(cdir=self.compile_dir, cfile=tcl_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da80d75-2347-406d-b8e6-fb8e786840a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'{cdir}''{cfile}'.format(cdir='./', cfile='../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d0abe5-4d56-4412-9b11-22dc606eaaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('vivado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "153a4265-19cc-4899-bfcf-ab3ac50b4aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"Submitted batch job 143\"\n",
    "int(a.replace(\"Submitted batch job \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad035678-fea8-4732-b672-e9d296acc618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Submitted batch job 143\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebbeb03e-b2f0-450a-a262-cf5e945d8c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'143'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.split(\"Submitted batch job \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9682b9-0dc9-4082-b2d6-1b8f4d0a0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if s1.startswith(s2):\n",
    "    s3 = s1.replace(s2, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f71c13-a6a4-4c65-a22b-51dc2e8e2a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedd8be-fcae-4f66-bca8-70fd69472268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50652e15-ad01-439b-b74c-0a8723b301d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a59b0f06-198b-4d04-bcf7-da6bd3ee9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "    from tempfile import NamedTemporaryFile\n",
    "    def generate_slurm_job_file():\n",
    "\n",
    "        str_num_nodes = f\"#SBATCH --nodes=\" + str(5) + f\"\\n\"\n",
    "        str_cpus_per_node = f\"#SBATCH --ntasks-per-node=\" + str(6) + f\"\\n\"\n",
    "        str_gpus_per_cpu = f\"#SBATCH --gres=gpu:\" + str(7) + f\"\\n\"\n",
    "        \n",
    "        file_data = f\"\"\n",
    "        file_data += f\"#!/bin/bash\\n\"\n",
    "        file_data += \"#SBATCH -o job.%j.out\\n\"\n",
    "        file_data += \"#SBATCH --partition=p40\\n\"\n",
    "        file_data += \"#SBATCH -J myFirstJob\\n\"\n",
    "        file_data += str_num_nodes\n",
    "        file_data += str_cpus_per_node\n",
    "        file_data += str_gpus_per_cpu\n",
    "        file_data += \"cd /raid/slurm-for-quantum/home/qc01/cyc/TeD-Q/tedq/distributed_worker/\\n\"\n",
    "        file_data += \"rank=$(($SLURM_PROCID+1))\\n\"\n",
    "        file_data += \"srun python rpc_workers.py --num_nodes 2 --rank $rank --gpus_per_cpu 4 --cpus_per_node 1 --master_addr 172.17.224.177\\n\"\n",
    "\n",
    "\n",
    "        fp = NamedTemporaryFile(mode='w+t', encoding=\"utf-8\", newline='\\n') # 创建一个临时文件\n",
    "        fp.write(file_data)     # 向该零时文件中写入一些数据\n",
    "        print(fp.read())\n",
    "\n",
    "        return fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2fd1e3e-4a61-416b-a9de-3420ca847a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = generate_slurm_job_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bc87a78-da54-4926-a674-8056083e4261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tempfile._TemporaryFileWrapper at 0x7f5be8401cd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e55ad468-22d2-48ad-8622-63bbc652f302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpashfh8ff'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55759fb0-1207-4a69-8848-e9673b75a079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ece314f5-b249-4b15-abae-fdbf43c0f572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "        str_num_nodes = \"#SBATCH --nodes=\" + str(5) + \"\\n\"\n",
    "        str_cpus_per_node = \"#SBATCH --ntasks-per-node=\" + str(6) + \"\\n\"\n",
    "        str_gpus_per_cpu = \"#SBATCH --gres=gpu:\" + str(7) + \"\\n\"\n",
    "        \n",
    "        file_data = \"\"\n",
    "        file_data += \"#!/bin/bash\\n\"\n",
    "        file_data += \"#SBATCH -o job.%j.out\\n\"\n",
    "        file_data += \"#SBATCH --partition=p40\\n\"\n",
    "        file_data += \"#SBATCH -J myFirstJob\\n\"\n",
    "        file_data += str_num_nodes\n",
    "        file_data += str_cpus_per_node\n",
    "        file_data += str_gpus_per_cpu\n",
    "        file_data += \"cd /raid/slurm-for-quantum/home/qc01/cyc/TeD-Q/tedq/distributed_worker/\\n\"\n",
    "        file_data += \"rank=$(($SLURM_PROCID+1))\\n\"\n",
    "        file_data += \"srun python rpc_workers.py --num_nodes 2 --rank $rank --gpus_per_cpu 4 --cpus_per_node 1 --master_addr 172.17.224.177\\n\"\n",
    "\n",
    "\n",
    "        fp = NamedTemporaryFile(mode='w+t', encoding=\"utf-8\", newline='\\n') # 创建一个临时文件\n",
    "        fp.write(file_data)     # 向该零时文件中写入一些数据\n",
    "        fp.write(f\"fuck\")\n",
    "        print(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7073185-5245-40e6-ac45-7213044dd21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5945374c-c60f-4342-adeb-9e271efc7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(**kwargs):\n",
    "    _a(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b07da5ee-8a75-4f38-942b-aadaf2e047f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _a(**kwargs):\n",
    "    print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7026d78-d222-43da-a0e5-eea2b082eb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 1, 'c': 2}\n"
     ]
    }
   ],
   "source": [
    "a(b=1, c=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaefb93-b230-4df0-acd1-7dd68686b96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f87d180-2016-463c-9a80-d05ea54e4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56b86b69-1821-47f1-a3fd-52cde97d4148",
   "metadata": {},
   "outputs": [],
   "source": [
    "    >>> dev = qml.device(\"default.qubit\", wires=(0, 1))\n",
    "    >>> @qml.qnode(dev)\n",
    "    ... def circuit():\n",
    "    ...     return qml.state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd55b126-91a1-40a1-94e6-5c49a91ca859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffde4d27-2afb-42aa-b175-49af349a9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tedq as qai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8197d5fa-2a72-4199-b1fa-15021a4153db",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_matrix = np.array([[0., 0.], [0., 1.]], dtype=np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7e1c8f1-8b1b-45bf-bac1-811c094ebba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tedq.QInterpreter.operators.qubit.Unitary at 0x7ff47d7bf250>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qai.Unitary(matrix=g_matrix, qubits=[0], do_queue=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c97bc445-5889-4af2-a20e-f0f47658e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=qml.Projector(np.array([1, 1]), wires=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "569325fe-a687-431e-979a-8b932f0cef5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [ 0., -0.,  0., -0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0., -0.,  0., -1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af6321c2-03ef-4e05-8058-0b63f7b4216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        g_matrix = np.array(\n",
    "            [\n",
    "            [0., 0., 0., 0.], \n",
    "            [0., 0., 0., 0.],\n",
    "            [0., 0., 0., 0.],\n",
    "            [0., 0., 0., 1.],\n",
    "            ], dtype=np.complex64)\n",
    "        g_matrix = g_matrix.reshape([2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29bd3a0e-dedd-4ef8-8148-507e9963c4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.+0.j, 0.+0.j],\n",
       "         [0.+0.j, 0.+0.j]],\n",
       "\n",
       "        [[0.+0.j, 0.+0.j],\n",
       "         [0.+0.j, 0.+0.j]]],\n",
       "\n",
       "\n",
       "       [[[0.+0.j, 0.+0.j],\n",
       "         [0.+0.j, 0.+0.j]],\n",
       "\n",
       "        [[0.+0.j, 0.+0.j],\n",
       "         [0.+0.j, 1.+0.j]]]], dtype=complex64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "844ebfa3-e44c-4d7d-a17d-47e7d4e5be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=qml.Projector(np.array([1]), wires=0) @ qml.PauliZ(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd6e6bbd-4bf2-47b4-9e57-9c1d9d035a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1.],\n",
    "       [0., 0., 1., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280ac75-0442-48d1-8624-1ecea68e7de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bec1e4-0fe7-45d1-b8e0-8e1844649573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ba1942-d55e-49c4-8e8b-6c833e4af031",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_default_to_fused_or_foreach' from 'torch.optim.optimizer' (/home/cyc/anaconda3/envs/cycenv/lib/python3.8/site-packages/torch/optim/optimizer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Optimizer, required, _use_grad_for_differentiable, _default_to_fused_or_foreach,\n\u001b[1;32m      4\u001b[0m                         _differentiable_doc, _foreach_doc, _maximize_doc)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_foreach_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _group_tensors_by_device_and_dtype\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_default_to_fused_or_foreach' from 'torch.optim.optimizer' (/home/cyc/anaconda3/envs/cycenv/lib/python3.8/site-packages/torch/optim/optimizer.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.optim.optimizer import (Optimizer, required, _use_grad_for_differentiable, _default_to_fused_or_foreach,\n",
    "                        _differentiable_doc, _foreach_doc, _maximize_doc)\n",
    "from typing import List, Optional\n",
    "from torch.utils._foreach_utils import _group_tensors_by_device_and_dtype\n",
    "\n",
    "__all__ = ['SGD', 'sgd']\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, params, lr=required, momentum=0, dampening=0,\n",
    "                 weight_decay=0, nesterov=False, *, maximize: bool = False, foreach: Optional[bool] = None,\n",
    "                 differentiable: bool = False):\n",
    "        if lr is not required and lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if momentum < 0.0:\n",
    "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
    "        if weight_decay < 0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "\n",
    "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n",
    "                        weight_decay=weight_decay, nesterov=nesterov,\n",
    "                        maximize=maximize, foreach=foreach,\n",
    "                        differentiable=differentiable)\n",
    "        if nesterov and (momentum <= 0 or dampening != 0):\n",
    "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('nesterov', False)\n",
    "            group.setdefault('maximize', False)\n",
    "            group.setdefault('foreach', None)\n",
    "            group.setdefault('differentiable', False)\n",
    "\n",
    "    def _init_group(self, group, params_with_grad, d_p_list, momentum_buffer_list):\n",
    "        has_sparse_grad = False\n",
    "\n",
    "        for p in group['params']:\n",
    "            if p.grad is not None:\n",
    "                params_with_grad.append(p)\n",
    "                d_p_list.append(p.grad)\n",
    "                if p.grad.is_sparse:\n",
    "                    has_sparse_grad = True\n",
    "\n",
    "                state = self.state[p]\n",
    "                if 'momentum_buffer' not in state:\n",
    "                    momentum_buffer_list.append(None)\n",
    "                else:\n",
    "                    momentum_buffer_list.append(state['momentum_buffer'])\n",
    "\n",
    "        return has_sparse_grad\n",
    "\n",
    "\n",
    "    @_use_grad_for_differentiable\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Args:\n",
    "            closure (Callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            params_with_grad = []\n",
    "            d_p_list = []\n",
    "            momentum_buffer_list = []\n",
    "\n",
    "            has_sparse_grad = self._init_group(group, params_with_grad, d_p_list, momentum_buffer_list)\n",
    "\n",
    "            sgd(params_with_grad,\n",
    "                d_p_list,\n",
    "                momentum_buffer_list,\n",
    "                weight_decay=group['weight_decay'],\n",
    "                momentum=group['momentum'],\n",
    "                lr=group['lr'],\n",
    "                dampening=group['dampening'],\n",
    "                nesterov=group['nesterov'],\n",
    "                maximize=group['maximize'],\n",
    "                has_sparse_grad=has_sparse_grad,\n",
    "                foreach=group['foreach'])\n",
    "\n",
    "            # update momentum_buffers in state\n",
    "            for p, momentum_buffer in zip(params_with_grad, momentum_buffer_list):\n",
    "                state = self.state[p]\n",
    "                state['momentum_buffer'] = momentum_buffer\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "SGD.__doc__ = r\"\"\"\\\n",
    "    Implements stochastic gradient descent (optionally with momentum).\n",
    "    .. math::\n",
    "       \\begin{aligned}\n",
    "            &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
    "            &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\theta_0 \\text{ (params)}, \\: f(\\theta)\n",
    "                \\text{ (objective)}, \\: \\lambda \\text{ (weight decay)},                          \\\\\n",
    "            &\\hspace{13mm} \\:\\mu \\text{ (momentum)}, \\:\\tau \\text{ (dampening)},\n",
    "            \\:\\textit{ nesterov,}\\:\\textit{ maximize}                                     \\\\[-1.ex]\n",
    "            &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
    "            &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
    "            &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n",
    "            &\\hspace{5mm}\\textbf{if} \\: \\lambda \\neq 0                                           \\\\\n",
    "            &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n",
    "            &\\hspace{5mm}\\textbf{if} \\: \\mu \\neq 0                                               \\\\\n",
    "            &\\hspace{10mm}\\textbf{if} \\: t > 1                                                   \\\\\n",
    "            &\\hspace{15mm} \\textbf{b}_t \\leftarrow \\mu \\textbf{b}_{t-1} + (1-\\tau) g_t           \\\\\n",
    "            &\\hspace{10mm}\\textbf{else}                                                          \\\\\n",
    "            &\\hspace{15mm} \\textbf{b}_t \\leftarrow g_t                                           \\\\\n",
    "            &\\hspace{10mm}\\textbf{if} \\: \\textit{nesterov}                                       \\\\\n",
    "            &\\hspace{15mm} g_t \\leftarrow g_{t} + \\mu \\textbf{b}_t                             \\\\\n",
    "            &\\hspace{10mm}\\textbf{else}                                                   \\\\[-1.ex]\n",
    "            &\\hspace{15mm} g_t  \\leftarrow  \\textbf{b}_t                                         \\\\\n",
    "            &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}                                          \\\\\n",
    "            &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} + \\gamma g_t                   \\\\[-1.ex]\n",
    "            &\\hspace{5mm}\\textbf{else}                                                    \\\\[-1.ex]\n",
    "            &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma g_t                   \\\\[-1.ex]\n",
    "            &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
    "            &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
    "            &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
    "       \\end{aligned}\n",
    "    Nesterov momentum is based on the formula from\n",
    "    `On the importance of initialization and momentum in deep learning`__.\n",
    "    \"\"\" + r\"\"\"\n",
    "    Args:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float): learning rate\n",
    "        momentum (float, optional): momentum factor (default: 0)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "        dampening (float, optional): dampening for momentum (default: 0)\n",
    "        nesterov (bool, optional): enables Nesterov momentum (default: False)\n",
    "        {maximize}\n",
    "        {foreach}\n",
    "        {differentiable}\n",
    "    \"\"\".format(maximize=_maximize_doc, foreach=_foreach_doc, differentiable=_differentiable_doc) + r\"\"\"\n",
    "    Example:\n",
    "        >>> # xdoctest: +SKIP\n",
    "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "        >>> optimizer.zero_grad()\n",
    "        >>> loss_fn(model(input), target).backward()\n",
    "        >>> optimizer.step()\n",
    "    __ http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf\n",
    "    .. note::\n",
    "        The implementation of SGD with Momentum/Nesterov subtly differs from\n",
    "        Sutskever et. al. and implementations in some other frameworks.\n",
    "        Considering the specific case of Momentum, the update can be written as\n",
    "        .. math::\n",
    "            \\begin{aligned}\n",
    "                v_{t+1} & = \\mu * v_{t} + g_{t+1}, \\\\\n",
    "                p_{t+1} & = p_{t} - \\text{lr} * v_{t+1},\n",
    "            \\end{aligned}\n",
    "        where :math:`p`, :math:`g`, :math:`v` and :math:`\\mu` denote the\n",
    "        parameters, gradient, velocity, and momentum respectively.\n",
    "        This is in contrast to Sutskever et. al. and\n",
    "        other frameworks which employ an update of the form\n",
    "        .. math::\n",
    "            \\begin{aligned}\n",
    "                v_{t+1} & = \\mu * v_{t} + \\text{lr} * g_{t+1}, \\\\\n",
    "                p_{t+1} & = p_{t} - v_{t+1}.\n",
    "            \\end{aligned}\n",
    "        The Nesterov version is analogously modified.\n",
    "        Moreover, the initial value of the momentum buffer is set to the\n",
    "        gradient value at the first step. This is in contrast to some other\n",
    "        frameworks that initialize it to all zeros.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def sgd(params: List[Tensor],\n",
    "        d_p_list: List[Tensor],\n",
    "        momentum_buffer_list: List[Optional[Tensor]],\n",
    "        # kwonly args with defaults are not supported by functions compiled with torchscript issue #70627\n",
    "        # setting this as kwarg for now as functional API is compiled by torch/distributed/optim\n",
    "        has_sparse_grad: bool = None,\n",
    "        foreach: Optional[bool] = None,\n",
    "        *,\n",
    "        weight_decay: float,\n",
    "        momentum: float,\n",
    "        lr: float,\n",
    "        dampening: float,\n",
    "        nesterov: bool,\n",
    "        maximize: bool):\n",
    "    r\"\"\"Functional API that performs SGD algorithm computation.\n",
    "    See :class:`~torch.optim.SGD` for details.\n",
    "    \"\"\"\n",
    "\n",
    "    if foreach is None:\n",
    "        # why must we be explicit about an if statement for torch.jit.is_scripting here?\n",
    "        # because JIT can't handle Optionals nor fancy conditionals when scripting\n",
    "        if not torch.jit.is_scripting():\n",
    "            _, foreach = _default_to_fused_or_foreach(params, differentiable=False, use_fused=False)\n",
    "        else:\n",
    "            foreach = False\n",
    "\n",
    "    if foreach and torch.jit.is_scripting():\n",
    "        raise RuntimeError('torch.jit.script not supported with foreach optimizers')\n",
    "\n",
    "    if foreach and not torch.jit.is_scripting():\n",
    "        func = _multi_tensor_sgd\n",
    "    else:\n",
    "        func = _single_tensor_sgd\n",
    "\n",
    "    func(params,\n",
    "         d_p_list,\n",
    "         momentum_buffer_list,\n",
    "         weight_decay=weight_decay,\n",
    "         momentum=momentum,\n",
    "         lr=lr,\n",
    "         dampening=dampening,\n",
    "         nesterov=nesterov,\n",
    "         has_sparse_grad=has_sparse_grad,\n",
    "         maximize=maximize)\n",
    "\n",
    "def _single_tensor_sgd(params: List[Tensor],\n",
    "                       d_p_list: List[Tensor],\n",
    "                       momentum_buffer_list: List[Optional[Tensor]],\n",
    "                       *,\n",
    "                       weight_decay: float,\n",
    "                       momentum: float,\n",
    "                       lr: float,\n",
    "                       dampening: float,\n",
    "                       nesterov: bool,\n",
    "                       maximize: bool,\n",
    "                       has_sparse_grad: bool):\n",
    "\n",
    "    for i, param in enumerate(params):\n",
    "        d_p = d_p_list[i] if not maximize else -d_p_list[i]\n",
    "\n",
    "        if weight_decay != 0:\n",
    "            d_p = d_p.add(param, alpha=weight_decay)\n",
    "\n",
    "        if momentum != 0:\n",
    "            buf = momentum_buffer_list[i]\n",
    "\n",
    "            if buf is None:\n",
    "                buf = torch.clone(d_p).detach()\n",
    "                momentum_buffer_list[i] = buf\n",
    "            else:\n",
    "                buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n",
    "\n",
    "            if nesterov:\n",
    "                d_p = d_p.add(buf, alpha=momentum)\n",
    "            else:\n",
    "                d_p = buf\n",
    "\n",
    "        param.add_(d_p, alpha=-lr)\n",
    "\n",
    "\n",
    "def _multi_tensor_sgd(params: List[Tensor],\n",
    "                      grads: List[Tensor],\n",
    "                      momentum_buffer_list: List[Optional[Tensor]],\n",
    "                      *,\n",
    "                      weight_decay: float,\n",
    "                      momentum: float,\n",
    "                      lr: float,\n",
    "                      dampening: float,\n",
    "                      nesterov: bool,\n",
    "                      maximize: bool,\n",
    "                      has_sparse_grad: bool):\n",
    "\n",
    "    if len(params) == 0:\n",
    "        return\n",
    "\n",
    "    grouped_tensors = _group_tensors_by_device_and_dtype([params, grads, momentum_buffer_list], with_indices=True)\n",
    "    for device_params, device_grads, device_momentum_buffer_list, indices in grouped_tensors.values():\n",
    "        device_has_sparse_grad = any(grad.is_sparse for grad in device_grads)\n",
    "\n",
    "        if maximize:\n",
    "            device_grads = torch._foreach_neg(tuple(device_grads))  # type: ignore[assignment]\n",
    "\n",
    "        if weight_decay != 0:\n",
    "            device_grads = torch._foreach_add(device_grads, device_params, alpha=weight_decay)\n",
    "\n",
    "        if momentum != 0:\n",
    "            bufs = []\n",
    "\n",
    "            all_states_with_momentum_buffer = True\n",
    "            for i in range(len(device_momentum_buffer_list)):\n",
    "                if device_momentum_buffer_list[i] is None:\n",
    "                    all_states_with_momentum_buffer = False\n",
    "                    break\n",
    "                else:\n",
    "                    bufs.append(device_momentum_buffer_list[i])\n",
    "\n",
    "            if all_states_with_momentum_buffer:\n",
    "                torch._foreach_mul_(bufs, momentum)\n",
    "                torch._foreach_add_(bufs, device_grads, alpha=1 - dampening)\n",
    "            else:\n",
    "                bufs = []\n",
    "                for i in range(len(device_momentum_buffer_list)):\n",
    "                    if device_momentum_buffer_list[i] is None:\n",
    "                        buf = device_momentum_buffer_list[i] = momentum_buffer_list[indices[i]] = \\\n",
    "                            torch.clone(device_grads[i]).detach()\n",
    "                    else:\n",
    "                        buf = device_momentum_buffer_list[i]\n",
    "                        buf.mul_(momentum).add_(device_grads[i], alpha=1 - dampening)\n",
    "\n",
    "                    bufs.append(buf)\n",
    "\n",
    "            if nesterov:\n",
    "                torch._foreach_add_(device_grads, bufs, alpha=momentum)\n",
    "            else:\n",
    "                device_grads = bufs\n",
    "\n",
    "        if not device_has_sparse_grad:\n",
    "            torch._foreach_add_(device_params, device_grads, alpha=-lr)\n",
    "        else:\n",
    "            # foreach APIs don't support sparse\n",
    "            for i in range(len(device_params)):\n",
    "                device_params[i].add_(device_grads[i], alpha=-lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f95757-8c80-431f-994b-81d9f0a7e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bde1476-fc09-43a0-8908-809cb2051d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD as sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cec01323-3873-45a1-8dce-2400cb7c47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class abc(sgd):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "765aa025-e6a5-40c2-ad87-8d4dbe9192b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abc (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.3\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([4.])\n",
    "abc([a], lr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "deeafdd6-7ae6-4d2d-9b81-f74efae70cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, params, lr=required, momentum=0, dampening=0,\n",
    "                 weight_decay1=0, weight_decay2=0, nesterov=False):\n",
    "        print(params)\n",
    "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n",
    "                        weight_decay1=weight_decay1, weight_decay2=weight_decay2, nesterov=nesterov)\n",
    "        if nesterov and (momentum <= 0 or dampening != 0):\n",
    "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
    "        super(SGD, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(SGD, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('nesterov', False)\n",
    "\n",
    "    def step(self, metric_tensor, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            weight_decay1 = group['weight_decay1']\n",
    "            weight_decay2 = group['weight_decay2']\n",
    "            momentum = group['momentum']\n",
    "            dampening = group['dampening']\n",
    "            nesterov = group['nesterov']\n",
    "            \n",
    "\n",
    "            d_p_list = []\n",
    "            p_list = []\n",
    "            for p in group['params']:\n",
    "                print(p)\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                if weight_decay1 != 0:\n",
    "                    d_p.add_(weight_decay1, torch.sign(p.data))\n",
    "                if weight_decay2 != 0:\n",
    "                    d_p.add_(weight_decay2, p.data)\n",
    "                if momentum != 0:\n",
    "                    param_state = self.state[p]\n",
    "                    if 'momentum_buffer' not in param_state:\n",
    "                        buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n",
    "                        buf.mul_(momentum).add_(d_p)\n",
    "                    else:\n",
    "                        buf = param_state['momentum_buffer']\n",
    "                        buf.mul_(momentum).add_(1 - dampening, d_p)\n",
    "                    if nesterov:\n",
    "                        d_p = d_p.add(momentum, buf)\n",
    "                    else:\n",
    "                        d_p = buf\n",
    "\n",
    "                #p.data.add_(-group['lr'], d_p)\n",
    "                p_list.append(p)\n",
    "                d_p_list.append(d_p)\n",
    "            \n",
    "            print(p_list, d_p_list)\n",
    "            grad_flat = torch.tensor(d_p_list)\n",
    "            x_flat = torch.tensor(p_list)\n",
    "            stepsize = group['lr']\n",
    "            \n",
    "            x_new_flat = x_flat - stepsize * torch.linalg.solve(metric_tensor, grad_flat)\n",
    "            print(x_new_flat)\n",
    "            \n",
    "            for i, p in enumerate(group['params']):\n",
    "                p.data = x_new_flat[i].data\n",
    "                \n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c679f2f-0627-4b10-b940-8d3ef66ffaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_tensor = torch.tensor([[1., 0.], [0., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0fcf3a3c-83d9-4109-aa86-f808c48f569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [torch.tensor([4.], requires_grad=True), torch.tensor([2.], requires_grad=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4de1c861-1225-460e-9858-da4d39a01a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.sum(a[0]+a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bd2f45b1-b245-4e34-8847-5efb976353bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ad5545d-84f9-40fe-863a-a47779ab2dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([4.], requires_grad=True), tensor([2.], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "b = SGD(a, lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4592b4fa-f7ad-490e-9bf6-d3c639a1cb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8000, requires_grad=True)\n",
      "tensor(1.8000, requires_grad=True)\n",
      "[tensor(3.8000, requires_grad=True), tensor(1.8000, requires_grad=True)] [tensor([1.]), tensor([1.])]\n",
      "tensor([3.7000, 1.7000])\n"
     ]
    }
   ],
   "source": [
    "b.step(metric_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e828b3b4-598c-4fb2-89f1-59008066e946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(3.7000, requires_grad=True), tensor(1.7000, requires_grad=True)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c981a3-c53b-456c-8f1f-e7661825cd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
