{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7dc858",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Qubit rotation\n",
    "\n",
    "This example shows the basic operation of machine learning framework with a quantum device. A qubit is initilized with a arbitary Rx and Ry rotation and the target state is pure |1> state. After several steps of the iteration. The rotation angle of Rx and Ry will converge to 0 and pi. \n",
    "\n",
    "### About this example\n",
    "The example contains the model compiled with three different configurations of backends and interfaces -- JAX backend, JAX backend with pytorch interface and pytorch backend.\n",
    "The example also shows how to use state vector propagation mode and tensor network contraction mode. And two methods for obtaining gradient -- back propagation and parameter shift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496147a8",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2359d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tedq as qai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bda454",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define the quantum model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88114ab",
   "metadata": {},
   "source": [
    "### Define the circuit with TeD-Q framework\n",
    "#### (Remember, if you have multiple measurements, all the measurement results should has the same shape!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391463f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quantum circuit\n",
    "def circuitDef(params):\n",
    "    qai.RX(params[0], qubits=[0])\n",
    "    qai.RY(params[1], qubits=[0])\n",
    "    return qai.expval(qai.PauliZ(qubits=[0]))\n",
    "\n",
    "number_of_qubits = 1\n",
    "parameter_shapes = [(2,)]\n",
    "\n",
    "# Quantum circuit construction\n",
    "circuit = qai.Circuit(circuitDef, number_of_qubits, parameter_shapes = parameter_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb24529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of the quantum circuit\n",
    "drawer = qai.matplotlib_drawer(circuit)\n",
    "drawer.draw_circuit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bfa98e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Circuit compiled with JAX backend\n",
    "Gradient will obtain from backpropagation by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5943f0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### state vector propagation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7315fe6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_compilecircuit = circuit.compilecircuit(backend=\"jax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b990a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tensor network contraction mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081917e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Use CoTenGra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55658bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# slicing_opts = {'target_size': 2**28}\n",
    "# hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':12, 'progbar':True, 'minimize':'flops', 'parallel':True, 'slicing_opts':slicing_opts}\n",
    "# import cotengra as ctg\n",
    "# my_compilecircuit = circuit.compilecircuit(backend=\"jax\", use_cotengra=ctg, hyper_opt = hyper_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc1347",
   "metadata": {},
   "source": [
    "#### Use JDtensorPath (Suggested)\n",
    "1. 'target_num_slices' is useful if you want to do the contraction in parallel, it will devide the tensor network into pieces and then calculat them in parallel\n",
    "2. 'math_repeats' means how many times are going to run JDtensorPath to find a best contraction path\n",
    "3. 'search_parallel' means to run the JDtensorPath in parallel, True means to use all the CPUs, integer number means to use that number of CPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jdtensorpath import JDOptTN as jdopttn\n",
    "slicing_opts = {'target_size':2**28, 'repeats':500, 'target_num_slices':None, 'contract_parallel':False}\n",
    "hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':12, 'search_parallel':True, 'slicing_opts':slicing_opts}\n",
    "my_compilecircuit = circuit.compilecircuit(backend=\"jax\", use_jdopttn=jdopttn, hyper_opt = hyper_opt, tn_simplify = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1943e7f",
   "metadata": {},
   "source": [
    "### Define cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b076eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(*params):\n",
    "    return my_compilecircuit(*params)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = (0.011, 0.012)\n",
    "cost(*new_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac31e0",
   "metadata": {},
   "source": [
    "### Define optimizer\n",
    "TeD-Q built-in optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer = qai.GradientDescentOptimizer(cost, [0, 1], 0.4, interface=\"jax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a24b2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034de72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_params = (0.011, 0.012)\n",
    "for i in range(100):\n",
    "    new_params = Optimizer.step(*new_params)\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(\"Cost after step {:5d}: {: .7f}\".format(i + 1, cost(*new_params)))\n",
    "        print(\"Parameters after step {:5d}: {}\".format(i + 1, new_params))\n",
    "print(new_params)\n",
    "print(cost(*new_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d4d325",
   "metadata": {},
   "source": [
    "### Trained circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedCircuit = qai.Circuit(circuitDef, 1, new_params)\n",
    "drawer = qai.matplotlib_drawer(trainedCircuit)\n",
    "drawer.full_draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb1078",
   "metadata": {},
   "source": [
    "# Circuit compiled with JAX backend and pytorch interface\n",
    "Gradient will obtain from backpropagation by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02623248",
   "metadata": {
    "tags": []
   },
   "source": [
    "### state vector propagation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c29d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_compilecircuit = circuit.compilecircuit(backend=\"jax\", interface=\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110e6f1-0b27-44cb-9b5f-0b6d7d8a43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jnp\n",
    "a = jnp.array([[1,2],[2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f9bff-d5a2-4321-bc7c-632afb644a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74909b0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tensor network contraction mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c8f160",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### by using cotengra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e2d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slicing_opts = {'target_size': 2**28}\n",
    "hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':12, 'progbar':True, 'minimize':'flops', 'parallel':True, 'slicing_opts':slicing_opts}\n",
    "import cotengra as ctg\n",
    "my_compilecircuit = circuit.compilecircuit(backend=\"jax\", use_cotengra=ctg, hyper_opt = hyper_opt, interface=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ddf7a",
   "metadata": {},
   "source": [
    "#### Use JDtensorPath (Suggested)\n",
    "1. 'target_num_slices' is useful if you want to do the contraction in parallel, it will devide the tensor network into pieces and then calculat them in parallel\n",
    "2. 'math_repeats' means how many times are going to run JDtensorPath to find a best contraction path\n",
    "3. 'search_parallel' means to run the JDtensorPath in parallel, True means to use all the CPUs, integer number means to use that number of CPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cdf211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jdtensorpath import JDOptTN as jdopttn\n",
    "# slicing_opts = {'target_size':2**28, 'repeats':500, 'target_num_slices':None, 'contract_parallel':False}\n",
    "# hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':12, 'search_parallel':True, 'slicing_opts':slicing_opts}\n",
    "# my_compilecircuit = circuit.compilecircuit(backend=\"jax\", use_jdopttn=jdopttn, hyper_opt = hyper_opt, tn_simplify = False, interface=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b472f32",
   "metadata": {},
   "source": [
    "### Define cost function and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca301b2",
   "metadata": {},
   "source": [
    "### Define cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(*params):\n",
    "    return my_compilecircuit(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using TeD-Q built-in optimizer\n",
    "Optimizer = qai.GradientDescentOptimizer(cost, [0, 1], 0.4, interface=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39a40c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([0.011], requires_grad= True)\n",
    "b = torch.tensor([0.012], requires_grad= True)\n",
    "my_params = (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da99f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_params = my_params\n",
    "for i in range(100):\n",
    "    new_params = Optimizer.step(*new_params)\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(\"Cost after step {:5d}: {}\".format(i + 1, cost(*new_params)))\n",
    "        print(\"Parameters after step {:5d}: {}\".format(i + 1, new_params))\n",
    "print(new_params)\n",
    "print(cost(*new_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d77df",
   "metadata": {},
   "source": [
    "### Trained circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c84abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedCircuit = qai.Circuit(circuitDef, 1, new_params)\n",
    "drawer = qai.matplotlib_drawer(trainedCircuit)\n",
    "drawer.full_draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bf875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "623ff679",
   "metadata": {},
   "source": [
    "# Circuit compiled with pytorch backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14cac3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Gradient will obtain from backpropagation by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010154df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### state vector propagation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72fbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# my_compilecircuit = circuit.compilecircuit(backend=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6051a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tensor network contraction mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be7e18",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Use CoTenGra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094402bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# slicing_opts = {'target_size': 2**28}\n",
    "# hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':12, 'progbar':True, 'minimize':'flops', 'parallel':True, 'slicing_opts':slicing_opts}\n",
    "# import cotengra as ctg\n",
    "# my_compilecircuit = circuit.compilecircuit(backend=\"pytorch\", use_cotengra=ctg, hyper_opt = hyper_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba324828",
   "metadata": {},
   "source": [
    "#### Use JDtensorPath (Suggested)\n",
    "1. 'target_num_slices' is useful if you want to do the contraction in parallel, it will devide the tensor network into pieces and then calculat them in parallel\n",
    "2. 'math_repeats' means how many times are going to run JDtensorPath to find a best contraction path\n",
    "3. 'search_parallel' means to run the JDtensorPath in parallel, True means to use all the CPUs, integer number means to use that number of CPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jdtensorpath import JDOptTN as jdopttn\n",
    "slicing_opts = {'target_size':2**28, 'repeats':500, 'target_num_slices':None, 'contract_parallel':False}\n",
    "hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':12, 'search_parallel':True, 'slicing_opts':slicing_opts}\n",
    "my_compilecircuit = circuit.compilecircuit(backend=\"pytorch\", use_jdopttn=jdopttn, hyper_opt = hyper_opt, tn_simplify = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd16662",
   "metadata": {},
   "source": [
    "### Define cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(*params):\n",
    "    results = my_compilecircuit(*params)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b174b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using TeD-Q built-in optimizer\n",
    "Optimizer = qai.GradientDescentOptimizer(cost, [0, 1], 0.4, interface=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c183866",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94747b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([0.54], requires_grad= True)\n",
    "b = torch.tensor([0.12], requires_grad= True)\n",
    "my_params = (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d49951",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_params = my_params\n",
    "for i in range(100):\n",
    "    new_params = Optimizer.step(*new_params)\n",
    "    if (i + 1) % 1 == 0:\n",
    "        print(\"Cost after step {:5d}: {}\".format(i + 1, cost(*new_params)))\n",
    "        print(\"Parameters after step {:5d}: {}\".format(i + 1, new_params))\n",
    "print(new_params)\n",
    "print(cost(*new_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized rotation angles: {}\".format(new_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cost: {}\".format(cost(*new_params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf430d",
   "metadata": {},
   "source": [
    "### Using backend's optimizer and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef61d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam([a, b], lr=0.1)\n",
    "for i in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    #print(b.grad)\n",
    "    loss = cost(*my_params)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(\"Cost after step {:5d}: {}\".format(i + 1, cost(*new_params)))\n",
    "        print(\"Parameters after step {:5d}: {}\".format(i + 1, new_params))\n",
    "print(new_params)\n",
    "print(cost(*new_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22cefb",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Obtain gradient by parameter shift method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498a55c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### state vector propagation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b66344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# my_compilecircuit = circuit.compilecircuit(backend=\"pytorch\", diff_method = \"param_shift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ea829",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tensor network contraction mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb525f46",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Use CoTenGra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08643b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# slicing_opts = {'target_size': 2**28}\n",
    "# hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':12, 'progbar':True, 'minimize':'flops', 'parallel':True, 'slicing_opts':slicing_opts}\n",
    "# import cotengra as ctg\n",
    "# my_compilecircuit = circuit.compilecircuit(backend=\"pytorch\", use_cotengra=ctg, hyper_opt = hyper_opt, diff_method = \"param_shift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973bdaad",
   "metadata": {},
   "source": [
    "#### Use JDtensorPath (Suggested)\n",
    "1. 'target_num_slices' is useful if you want to do the contraction in parallel, it will devide the tensor network into pieces and then calculat them in parallel\n",
    "2. 'math_repeats' means how many times are going to run JDtensorPath to find a best contraction path\n",
    "3. 'search_parallel' means to run the JDtensorPath in parallel, True means to use all the CPUs, integer number means to use that number of CPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d051a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jdtensorpath import JDOptTN as jdopttn\n",
    "slicing_opts = {'target_size':2**28, 'repeats':500, 'target_num_slices':None, 'contract_parallel':False}\n",
    "hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':12, 'search_parallel':True, 'slicing_opts':slicing_opts}\n",
    "my_compilecircuit = circuit.compilecircuit(backend=\"pytorch\", use_jdopttn=jdopttn, hyper_opt = hyper_opt, tn_simplify = False, diff_method = \"param_shift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c587a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca28db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(*params):\n",
    "    results = my_compilecircuit(*params)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad4035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using TeD-Q built-in optimizer\n",
    "Optimizer = qai.GradientDescentOptimizer(cost, [0, 1], 0.4, interface=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebad5be",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6928ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([0.54], requires_grad= True)\n",
    "b = torch.tensor([0.12], requires_grad= True)\n",
    "my_params = (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_params = my_params\n",
    "for i in range(100):\n",
    "    new_params = Optimizer.step(*new_params)\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(\"Cost after step {:5d}: {}\".format(i + 1, cost(*new_params)))\n",
    "        print(\"Parameters after step {:5d}: {}\".format(i + 1, new_params))\n",
    "print(new_params)\n",
    "print(cost(*new_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c50308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized rotation angles: {}\".format(new_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fa229",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cost: {}\".format(cost(*new_params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0df62",
   "metadata": {},
   "source": [
    "### Using backend's optimizer and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abfb309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam([a, b], lr=0.1)\n",
    "for i in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    #print(b.grad)\n",
    "    loss = cost(*my_params)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(\"Cost after step {:5d}: {}\".format(i + 1, cost(*new_params)))\n",
    "        print(\"Parameters after step {:5d}: {}\".format(i + 1, new_params))\n",
    "print(new_params)\n",
    "print(cost(*new_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d601fee0",
   "metadata": {},
   "source": [
    "### Trained circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f485a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedCircuit = qai.Circuit(circuitDef, 1, new_params)\n",
    "drawer = qai.matplotlib_drawer(trainedCircuit)\n",
    "drawer.full_draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8dec7c-da9c-4566-8379-2e6cde05133d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6874b61b-88ad-464e-83a8-267d17306af0",
   "metadata": {},
   "source": [
    "# Real quantum computer hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc57e3-65c1-4fd8-a832-63ac00f2cc59",
   "metadata": {},
   "source": [
    "#### pytorch interface, parameter shift gradient method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87241d76-75b3-4fd1-a29c-248922f1f136",
   "metadata": {},
   "source": [
    "#### now only support 1 qubit PauliZ measurement, will be upgrade later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc0c0e-f692-4c1f-ba79-c38a2b197d66",
   "metadata": {},
   "source": [
    "#### check your jobs here: https://quantum-computing.ibm.com/jobs?jobs=circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6ef3a-28a5-4e2c-9d25-4a775dcb8086",
   "metadata": {},
   "source": [
    "#### caution, this is extremely slow since so many people are queuing for IBMQ free quantum computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846cea7c-9157-432b-a05f-99f35be222f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import IBMQ\n",
    "IBMQ.enable_account('your IBMQ token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c96536b-04fc-4225-8d3c-d9994ffdc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_compilecircuit = circuit.compilecircuit(backend=\"IBMQ_hardware\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba326f6-ddf6-4c71-8ea4-77b3ad46a80d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b2b9c-05c7-4f9c-a0a6-ef2512c74c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(*params):\n",
    "    results = my_compilecircuit(*params)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932e0a7-27b8-4946-b8bc-4fa8d680d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using TeD-Q built-in optimizer\n",
    "Optimizer = qai.GradientDescentOptimizer(cost, [0, 1], 0.8, interface=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3795a7ea-47d5-4883-9811-47bda76a808e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc73a1f-3ebd-4c19-8b76-48bf19a05fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([0.54], requires_grad= True)\n",
    "b = torch.tensor([0.12], requires_grad= True)\n",
    "my_params = (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73ad34-90dc-4282-80b3-35d28623c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost(*my_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d513cce-589b-4bab-b2c3-e5942ccf1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_params = my_params\n",
    "for i in range(10):\n",
    "    new_params = Optimizer.step(*new_params)\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(\"Parameters after step {:5d}: {}\".format(i + 1, new_params))\n",
    "print(new_params)\n",
    "print(cost(*new_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3bc5b-da43-4efc-9661-9dabfcbd6ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
