{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f14362f",
   "metadata": {},
   "source": [
    "# Quanvolution neural network\n",
    "This example is based on the [paper](https://arxiv.org/abs/1904.04767): \n",
    "\n",
    "```Quanvolutional Neural Networks: Powering Image Recognition with Quantum Circuits.``` \n",
    "\n",
    "This example aimed at showing the performance and the usage of the new quantum processing framework -- JDQAI. \n",
    "\n",
    "## Quanvolution layer\n",
    "The quantum convolution layer, a.k.a quanvolution layer, is a model providing a non-linear convolutional transformation of images, which can provide similar performance to classical non-linear transformation. The main goal is to find the quantum advantage in the non-linear transformation process. \n",
    "\n",
    "<img src=\"images/quanv.png\" width=1000 />\n",
    "(from ArXiv:1904.04767)\n",
    "\n",
    "## About this example\n",
    "In this example, the main struture of the example follow the one provided by [Pennylane](https://pennylane.ai/qml/demos/tutorial_quanvolution.html). The quanvolution transformation is done by a randomly generated quantum circuit. The images are pre-processed by the quanvolution layer and feed into a classical neural network. The performance of the quanvolution is comparing to a conventional convolution method in the end of the example. \n",
    "\n",
    "### MNIST Dataset\n",
    "MNIST is a database of handwritten digits. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf07fd4",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tedq as qai\n",
    "\n",
    "# Related package\n",
    "import torch\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe27c47a",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 3    # Number of random layers\n",
    "n_qubits = 4     # Number of qubits\n",
    "n_epochs = 50   # Number of optimization epochs\n",
    "n_train = 80    # Size of the train dataset\n",
    "n_test = 40     # Size of the test dataset\n",
    "\n",
    "np.random.seed(21)           # Seed for NumPy random number generator\n",
    "SAVE_PATH = \"./_data/quanvolution/\" # Data saving folder\n",
    "PREPROCESS = False           # If False, skip quantum processing and load data from SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dffdd3",
   "metadata": {},
   "source": [
    "# Load mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bae7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "\n",
    "# Reduce dataset size\n",
    "train_images = train_images[:n_train]\n",
    "train_labels = train_labels[:n_train]\n",
    "test_images = test_images[:n_test]\n",
    "test_labels = test_labels[:n_test]\n",
    "\n",
    "# Normalize pixel values within 0 and 1\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255\n",
    "\n",
    "# Add extra dimension for convolution channels\n",
    "train_images = np.array(train_images[..., tf.newaxis])\n",
    "test_images = np.array(test_images[..., tf.newaxis])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60119a9e",
   "metadata": {},
   "source": [
    "# Build a circuit for quanvolution process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8301dc4a",
   "metadata": {},
   "source": [
    "### Define the circuit with JDQAI framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n",
    "def circuitDef(phi):\n",
    "    for j in range(4):\n",
    "        qai.RY(np.pi * phi[j], qubits=[j])\n",
    "    # Generate random circuit    \n",
    "    qai.templates.RandomLayer(n_qubits, n_layers, 0.3, rand_params)\n",
    "    \n",
    "    exp_vals = [qai.measurement.expval(qai.PauliZ(qubits=[position])) for position in range(n_qubits)]\n",
    "    return exp_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb15703",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = qai.Circuit(circuitDef, n_qubits, torch.zeros(n_qubits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967bafd6",
   "metadata": {},
   "source": [
    "### Draw quantum circuit with circuit visualizer in JDQAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7faf61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer = qai.matplotlib_drawer(circuit)\n",
    "drawer.draw_circuit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae019b6",
   "metadata": {},
   "source": [
    "### Compile the circuit with pytorch backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "quanvCircuit = circuit.compilecircuit('pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad076176",
   "metadata": {},
   "source": [
    "# Pre-process the images with quanvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quanvolution(image):\n",
    "    \"\"\"Convolves the input image with many applications of the same quantum circuit.\"\"\"\n",
    "    out = np.zeros((14, 14, 4))\n",
    "\n",
    "    # Loop over the coordinates of the top-left pixel of 2X2 squares\n",
    "    for j in range(0, 28, 2):\n",
    "        for k in range(0, 28, 2):\n",
    "            # Process a squared 2x2 region of the image with a quantum circuit\n",
    "            q_results = quanvCircuit(\n",
    "                torch.tensor(\n",
    "                [\n",
    "                    image[j, k, 0],\n",
    "                    image[j, k + 1, 0],\n",
    "                    image[j + 1, k, 0],\n",
    "                    image[j + 1, k + 1, 0]\n",
    "                ]\n",
    "                )\n",
    "            )\n",
    "            # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
    "            for c in range(4):\n",
    "                out[j // 2, k // 2, c] = q_results[c]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ba8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS == True:\n",
    "    q_train_images = []\n",
    "    print(\"Quantum pre-processing of train images:\")\n",
    "    for idx, img in enumerate(train_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, n_train), end=\"\\r\")\n",
    "        q_train_images.append(quanvolution(img))\n",
    "    q_train_images = np.asarray(q_train_images)\n",
    "\n",
    "    q_test_images = []\n",
    "    print(\"\\nQuantum pre-processing of test images:\")\n",
    "    for idx, img in enumerate(test_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, n_test), end=\"\\r\")\n",
    "        q_test_images.append(quanvolution(img))\n",
    "    q_test_images = np.asarray(q_test_images)\n",
    "\n",
    "    # Save pre-processed images\n",
    "    np.save(SAVE_PATH + \"q_train_images.npy\", q_train_images)\n",
    "    np.save(SAVE_PATH + \"q_test_images.npy\", q_test_images)\n",
    "\n",
    "\n",
    "# Load pre-processed images\n",
    "q_train_images = np.load(SAVE_PATH + \"q_train_images.npy\")\n",
    "q_test_images = np.load(SAVE_PATH + \"q_test_images.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07032ec5",
   "metadata": {},
   "source": [
    "# Example output from quanvolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0099063",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 4\n",
    "n_channels = 4\n",
    "fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n",
    "for k in range(n_samples):\n",
    "    axes[0, 0].set_ylabel(\"Input\")\n",
    "    if k != 0:\n",
    "        axes[0, k].yaxis.set_visible(False)\n",
    "    axes[0, k].imshow(train_images[k, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "    # Plot all output channels\n",
    "    for c in range(n_channels):\n",
    "        axes[c + 1, 0].set_ylabel(\"Output [ch. {}]\".format(c))\n",
    "        if k != 0:\n",
    "            axes[c, k].yaxis.set_visible(False)\n",
    "        axes[c + 1, k].imshow(q_train_images[k, :, :, c], cmap=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf22489e",
   "metadata": {},
   "source": [
    "# Build quantum and classical model\n",
    "\n",
    "## Quantum model\n",
    "The model structure is \n",
    "```\n",
    "Quan > Flatten > Dense(10)\n",
    "```\n",
    "\n",
    "## Classical model\n",
    "The model structure is \n",
    "```\n",
    "Conv > Flatten > Dense(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27fb0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qModel():\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def cModel():\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(4, 2, 1, input_shape = (28, 28, 1), activation = 'relu'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b5f284",
   "metadata": {},
   "source": [
    "# Training classical and quantum model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_history = cModel().fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "\n",
    "q_history = qModel().fit(\n",
    "    q_train_images,\n",
    "    train_labels,\n",
    "    validation_data=(q_test_images, test_labels),\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5035cd",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax1.plot(q_history.history[\"val_accuracy\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax1.plot(c_history.history[\"val_accuracy\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(q_history.history[\"val_loss\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax2.plot(c_history.history[\"val_loss\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_ylim(top=2.5)\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "#fig.savefig(\"result.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
