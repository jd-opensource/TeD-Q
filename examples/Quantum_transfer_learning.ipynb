{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e013e5e",
   "metadata": {},
   "source": [
    "# Quantum Transfer learning\n",
    "\n",
    "In this example, we show the method to train quantum neural network with transfer learning method. We utilize the classical pre-trained model -- ResNet18 and replace its last fully-connected layer with the self-defined quantum model. \n",
    "\n",
    "## About this example\n",
    "In this example, the main struture of the example follow the one provided by [Pennylane](https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html). The core quantum operation of the framework is different from Pennylane. This example aimed at showing the performance and the usage of this new quantum processing framework -- TeD-Q. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe318ba8",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adfebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tedq as qai\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "torch.manual_seed(4)\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "np.random.seed(4)\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Others\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# OpenMP: number of parallel threads.\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "TF_CPP_MIN_LOG_LEVEL=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638bf1b6",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0646f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4                # Number of qubits\n",
    "step = 0.0004               # Learning rate\n",
    "batch_size = 4              # Number of samples for each training step\n",
    "num_epochs = 10              # Number of training epochs (for simple test, choose num_epochs to 1)\n",
    "q_depth = 6                 # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.01              # Initial spread of random quantum weights\n",
    "start_time = time.time()    # Start of the computation timer\n",
    "data_dir = \"./_data/hymenoptera_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c5569",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b38c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            # transforms.RandomResizedCrop(224),     # uncomment for data augmentation\n",
    "            # transforms.RandomHorizontalFlip(),     # uncomment for data augmentation\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            # Normalize input channels using mean values and standard deviations of ImageNet.\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x if x == \"train\" else \"validation\": datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), data_transforms[x]\n",
    "    )\n",
    "    for x in [\"train\", \"val\"]\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"validation\"]}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "\n",
    "# Initialize dataloader\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
    "    for x in [\"train\", \"validation\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c937c",
   "metadata": {},
   "source": [
    "## Initialize image plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c1440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image from tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # Inverse of the initial normalization operation.\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c352733",
   "metadata": {},
   "source": [
    "## Preview a set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders[\"validation\"]))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
    "    for x in [\"train\", \"validation\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03816b",
   "metadata": {},
   "source": [
    "# Define quantum model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c959f1",
   "metadata": {},
   "source": [
    "### template qunatum circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31389045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_layer(nqubits):\n",
    "    \"\"\"Layer of single-qubit Hadamard gates.\n",
    "    \"\"\"\n",
    "    for idx in range(nqubits):\n",
    "        qai.Hadamard(qubits=[idx])\n",
    "\n",
    "\n",
    "def RY_layer(w):\n",
    "    \"\"\"Layer of parametrized qubit rotations around the y axis.\n",
    "    \"\"\"\n",
    "    for idx, element in enumerate(w):\n",
    "        qai.RY(element, qubits=[idx])\n",
    "\n",
    "\n",
    "def entangling_layer(nqubits):\n",
    "    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\n",
    "    \"\"\"\n",
    "    # In other words it should apply something like :\n",
    "    # CNOT  CNOT  CNOT  CNOT...  CNOT\n",
    "    #   CNOT  CNOT  CNOT...  CNOT\n",
    "    for i in range(1, nqubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n",
    "        qai.CNOT(qubits=[i, i+1])\n",
    "    for i in range(0, nqubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n",
    "        qai.CNOT(qubits=[i, i+1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09815569",
   "metadata": {},
   "source": [
    "### Define the circuit with JDQAI framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuitDef(q_input_features, q_weights_flat):\n",
    "    \"\"\"\n",
    "    The variational quantum circuit.\n",
    "    \"\"\"\n",
    "    # Reshape weights\n",
    "#     q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "    q_weights = q_weights_flat.reshape((q_depth+1)*2, n_qubits)\n",
    "\n",
    "    # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "    H_layer(n_qubits)\n",
    "\n",
    "    # Embed features in the quantum node\n",
    "    RY_layer(q_input_features)\n",
    "\n",
    "    # Sequence of trainable variational layers\n",
    "#     for k in range(q_depth):\n",
    "#         entangling_layer(n_qubits)\n",
    "#         RY_layer(q_weights[k])\n",
    "    qai.templates.HardwareEfficient(n_qubits, q_depth, q_weights)\n",
    "#     qai.Templates.FullyConnected(n_qubits, q_depth, q_weights)\n",
    "    # Expectation values in the Z basis\n",
    "    exp_vals = [qai.expval(qai.PauliZ(qubits=[position])) for position in range(n_qubits)]\n",
    "    return tuple(exp_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a18df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = qai.Circuit(circuitDef, n_qubits, torch.zeros(n_qubits), torch.zeros((q_depth+1)*2, n_qubits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e1f92f",
   "metadata": {},
   "source": [
    "### Draw quantum circuit with circuit visualizer in JDQAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b26d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer = qai.matplotlib_drawer(circuit)\n",
    "drawer.full_draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6adc6f8",
   "metadata": {},
   "source": [
    "### Compile the circuit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53e06f",
   "metadata": {},
   "source": [
    "#### With pytorch backend and default back-propagation method and tensor contraction mode by using JDtensorPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jdtensorpath import JDOptTN as jdopttn\n",
    "slicing_opts = None#{'target_size':2**28, 'repeats':328, 'target_num_slices':4, 'contract_parallel':False}\n",
    "hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':4, 'progbar':True, 'minimize':'size', 'search_parallel':True, 'slicing_opts':slicing_opts}\n",
    "compiledCircuit = circuit.compilecircuit(backend=\"pytorch\", use_jdopttn=jdopttn, hyper_opt = hyper_opt, tn_simplify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d91ba7",
   "metadata": {},
   "source": [
    "#### With pytorch backend and parameter-shift method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe5341",
   "metadata": {},
   "source": [
    "### Implement quantum neural network with pytorch NN interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fe3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DressedQuantumNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Torch module implementing the *dressed* quantum net.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.pre_net = nn.Linear(512, n_qubits)\n",
    "#         self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn((q_depth+1) * n_qubits*2))     \n",
    "        self.post_net = nn.Linear(n_qubits, 2)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "\n",
    "        # obtain the input features for the quantum circuit\n",
    "        # by reducing the feature dimension from 512 to 4\n",
    "        pre_out = self.pre_net(input_features)\n",
    "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
    "\n",
    "        # Apply the quantum circuit to each element of the batch and append to q_out\n",
    "        q_out = torch.Tensor(0, n_qubits)\n",
    "        q_out = q_out.to(device)\n",
    "        for elem in q_in:\n",
    "            #q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0)\n",
    "            #print(hxj(elem, self.q_params))\n",
    "            q_out_elem = compiledCircuit(elem, self.q_params).float().unsqueeze(0)\n",
    "            \n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "\n",
    "        # return the two-dimensional prediction from the postprocessing layer\n",
    "        return self.post_net(q_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c870cd2d",
   "metadata": {},
   "source": [
    "### Load pretrained model and exclude the parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8913603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model_hybrid.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4bde94",
   "metadata": {},
   "source": [
    "### Replace classical FC layer in the model with quantum neural network layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98418fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that model_hybrid.fc (fully-connected layer) is the last layer of ResNet18\n",
    "model_hybrid.fc = DressedQuantumNet()\n",
    "\n",
    "# Use CUDA or CPU according to the \"device\" object.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_hybrid = model_hybrid.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fca7dd",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ab272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, panel=None, linechart=None):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 10000.0  # Large arbitrary number\n",
    "    best_acc_train = 0.0\n",
    "    best_loss_train = 10000.0  # Large arbitrary number\n",
    "    print(\"Training started:\")\n",
    "    \n",
    "    if panel is not None:\n",
    "        panel.show()\n",
    "    if linechart is not None:\n",
    "        x=0.\n",
    "        y=0\n",
    "        linechart.update(x,y)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"validation\"]:\n",
    "            if phase == \"train\":\n",
    "                # Set model to training mode\n",
    "                model.train()\n",
    "            else:\n",
    "                # Set model to evaluate mode\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            n_batches = dataset_sizes[phase] // batch_size\n",
    "            it = 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                since_batch = time.time()\n",
    "                batch_size_ = len(inputs)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Track/compute gradient and make an optimization step only when training\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Print iteration results\n",
    "                running_loss += loss.item() * batch_size_\n",
    "                batch_corrects = torch.sum(preds == labels.data).item()\n",
    "                running_corrects += batch_corrects\n",
    "                print(\n",
    "                    \"Phase: {} Epoch: {}/{} Iter: {}/{} Batch time: {:.4f}\".format(\n",
    "                        phase,\n",
    "                        epoch + 1,\n",
    "                        num_epochs,\n",
    "                        it + 1,\n",
    "                        n_batches + 1,\n",
    "                        time.time() - since_batch,\n",
    "                    ),\n",
    "                    end=\"\\r\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                it += 1\n",
    "\n",
    "                    \n",
    "            # Print epoch results\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            print(\n",
    "                \"Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        \".format(\n",
    "                    \"train\" if phase == \"train\" else \"validation  \",\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    epoch_loss,\n",
    "                    epoch_acc,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            if phase == \"validation\":\n",
    "                if panel is not None:\n",
    "                    panel.update(epoch_acc*100.)\n",
    "                if linechart is not None:\n",
    "                    x=time.time()-since\n",
    "                    y=epoch_acc\n",
    "                    linechart.update(x,y)\n",
    "\n",
    "            # Check if this is the best model wrt previous epochs\n",
    "            if phase == \"validation\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == \"validation\" and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "            if phase == \"train\" and epoch_acc > best_acc_train:\n",
    "                best_acc_train = epoch_acc\n",
    "            if phase == \"train\" and epoch_loss < best_loss_train:\n",
    "                best_loss_train = epoch_loss\n",
    "\n",
    "            # Update learning rate\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "                \n",
    "    if linechart is not None:\n",
    "        linechart.show()\n",
    "\n",
    "    # Print final results\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Training completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60)\n",
    "    )\n",
    "    print(\"Best test loss: {:.4f} | Best test accuracy: {:.4f}\".format(best_loss, best_acc))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f55eaa",
   "metadata": {},
   "source": [
    "### Define Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b034ee4",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968cbbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_hybrid = optim.Adam(model_hybrid.fc.parameters(), lr=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "    optimizer_hybrid, step_size=10, gamma=gamma_lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed757421",
   "metadata": {},
   "source": [
    "### initialize real-time monitor for QAI training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a01a8",
   "metadata": {},
   "source": [
    "#### Monitor with accuracy v.s Time chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8260f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = qai.Linechart()#accuracy vs time plot\n",
    "model_hybrid = train_model(model_hybrid, criterion, optimizer_hybrid, exp_lr_scheduler, \n",
    "                           num_epochs=5,linechart=chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163eabb",
   "metadata": {},
   "source": [
    "#### Monitor with accuracy panel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ed67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panel = qai.Panel()#Accuracy panel plot\n",
    "# model_hybrid = train_model(model_hybrid, criterion, optimizer_hybrid, exp_lr_scheduler, \n",
    "#                            num_epochs=num_epochs,panel=panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e33c1",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6cface",
   "metadata": {},
   "source": [
    "### Trained quantum circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawer = qai.matplotlib_drawer(compiledCircuit)\n",
    "#drawer.full_draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7af5f",
   "metadata": {},
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6, fig_name=\"Predictions\"):\n",
    "    images_so_far = 0\n",
    "    _fig = plt.figure(fig_name)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _i, (inputs, labels) in enumerate(dataloaders[\"validation\"]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis(\"off\")\n",
    "                ax.set_title(\"[{}]\".format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "                if images_so_far == num_images:\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90694920",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_hybrid, num_images=batch_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3238ef1-81a1-4bf9-9caa-6d03ce385472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
